{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rFd2ZvhPWBb"
   },
   "source": [
    "# Training:\n",
    "\n",
    "This project uses a machine learning model of classification and segmentation. It is based on a U-Net architecture, which uses a set of images and binary masks to train. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build images and masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The set of images and binary masks used for training can be generated via **satproc_extract_chips**.  \n",
    "This tool uses an image (or a set of images) and a vectorial file to create another set of images of a specific size and their masks.\n",
    "In addition, several features can be included like the rescale option to bring the output with pixel values between 0 to 255. All of them are fully explained below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vector file contains many categories of objects, then the mask will have a binary band for each of them. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chips](img/mask_ej.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!satproc_extract_chips     \\\n",
    "    /home/ro/incendios-forestales/data/img/dif_nbr.tif \\\n",
    "    -o /home/ro/incendios-forestales/data/data_train/160_80/ \\\n",
    "    --size 160 \\    \n",
    "    --step-size 80 \\   \n",
    "    --aoi /home/ro/incendios-forestales/data/shp/gt/fuego.geojson \\\n",
    "    --labels /home/ro/incendios-forestales/data/shp/gt/fuego.geojson \\\n",
    "    --label-property 'class' \\\n",
    "    --classes 'fire' \\\n",
    "    --rescale \\\n",
    "    --rescale-mode percentiles \\\n",
    "    --upper-cut 98 --lower-cut 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!ls /home/ro/incendios-forestales/data/data_train/160_80/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### The options:\n",
    "\n",
    "* **the argument** the path to the source image or a folder with contains a set of images\n",
    "\n",
    "* **o** path to destiny images and masks\n",
    "* **size**size of the generated images and masks \n",
    "* **step-size** the size of the step in the slide windows process. if the step size is smaller than the size then an overlap is generated. This could be useful to increase the amount of training data.\n",
    "* **crs** it set an epsg in case the images don't have it. \n",
    "* **label-property** the name of the field in the shapefile where each category is defined. \n",
    "* **classes** name of the different categories (all split by a space)\n",
    "* **aoi** path to the shapefile that delimits the region of interest. It can be the same that the shapefile with the categories or other.\n",
    "* **rescale** to rescale the images to a range 1-255\n",
    "* **rescale-mode** Rescaled mode:  percentiles, custom_rgb, values. \n",
    "\n",
    "Percentiles mode will rescale each band if the image to a scale defined by the percentiles considering the upper and lower cuts. For example --upper-cut 98 --lower-cut 2\n",
    "\n",
    "The custom_rgb will rescale the 3 first bands from 0 to 0.3 and the rest of them considering the percentiles.\n",
    "\n",
    "The values mode will rescale all the bands in the image considering the min and max values defined. For example --Min 0 --Max 0.3   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainig  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we should import the libraries needed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from fire.unet.train import TrainConfig, train\n",
    "from fire.unet.evaluate import plot_data_generator\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To set the parameters of the training process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = TrainConfig(width=320,  #  size of the image (160, 320,etc)\n",
    "                     height=320,\n",
    "                     n_channels=1,  #  number of channels of the image rgb -> 3\n",
    "                     n_classes=1, # number of classes to clasify\n",
    "                     apply_image_augmentation=True, #  increase the amount of training data with a image augmentation process\n",
    "                     seed=42,\n",
    "                     epochs=15, \n",
    "                     batch_size=16, \n",
    "                     steps_per_epoch=150, \n",
    "                     early_stopping_patience=3, \n",
    "                     validation_split=0.2, \n",
    "                     images_path=os.path.join('/home/ro/incendios-forestales/data/data_train_1D_diffNBR','S2_1class', '160_80'), #ruta a las im√°genes\n",
    "                     model_path=os.path.join('/home/ro/incendios-forestales/data/weights/', 'UNet_fire_1Dim_160_80_spe150.h5'),#  ruta al archivo de entrenamiento\n",
    "                     evaluate=False,\n",
    "                     weights = [0.5]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot some exaples of images and masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_data_generator(train_config=train_config, num_samples=3, fig_size=(30,20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_config = train(train_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print some metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(16,4))\n",
    "\n",
    "plt.subplot(121)\n",
    "plt.plot(res_config.history['loss'])\n",
    "plt.plot(res_config.history['val_loss'])\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.plot(res_config.history['mean_iou'])\n",
    "plt.plot(res_config.history['val_mean_iou'])\n",
    "plt.title('mean_iou')\n",
    "plt.ylabel('val_mean_iou')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKlws8+6PcuvJrSWdSmTxJ",
   "include_colab_link": true,
   "name": "2 - Entrenamiento",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
