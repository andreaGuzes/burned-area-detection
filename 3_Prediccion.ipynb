{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0rFd2ZvhPWBb"
   },
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocesamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images for the prediction process are generated in the same way but in this case, the masks are not going to be created.\n",
    "In the prediction process, the size and the step-size must be the same to do not generate an overlap in the predicted results. However, there is no need that the images have the same size as the training images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!satproc_extract_chips     \\\n",
    "    /home/ro/incendios-forestales/data/img/dif_nbr.tif \\\n",
    "    -o /home/ro/incendios-forestales/data/data_predict/160_80/ \\\n",
    "    --size 800 \\    \n",
    "    --step-size 800 \\   \n",
    "    --rescale \\\n",
    "    --rescale-mode percentiles \\\n",
    "    --upper-cut 98 --lower-cut 2atproc_extract_chips \\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **--aoi** option is useful to reduce the predicction area to some shapefile."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "from fire.unet.predict import PredictConfig, predict, plot_data_results\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_config = PredictConfig(\n",
    "                                    images_path=os.path.join('./data/data_predict/','800_800'),\n",
    "                                    results_path=os.path.join('./data/data_result/','800_800'),\n",
    "                                    batch_size=16,\n",
    "                                    model_path=os.path.join('./data/weights/', 'UNet_fire_1Dim_160_80_spe150.h5'),  #  ruta al modelo (.h5)\n",
    "                                    height=160,\n",
    "                                    width=160,\n",
    "                                    n_channels=1,\n",
    "                                    n_classes=1)\n",
    "          \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(predict_config) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data_results(predict_config=predict_config, num_samples=3, fig_size=(30,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import tifffile as tiff\n",
    "from skimage.transform import resize\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import os\n",
    "H=10\n",
    "images = [os.path.basename(f) for f in sorted(glob(os.path.join(predict_config.results_path, '*.tif')))]\n",
    "\n",
    "# Sample\n",
    "#images = images[:H] \n",
    "images = random.sample(images, H)\n",
    "for img_file in images:\n",
    "    try:\n",
    "       #s2 3D\n",
    "        img_s2 = tiff.imread(os.path.join(predict_config.images_path, 'images', img_file))\n",
    "        img_s2 = minmax_scale(img_s2.ravel(), feature_range=(0, 255)).reshape(img_s2.shape)\n",
    "        img_s2 = resize(img_s2, (predict_config.height, predict_config.width), mode='constant', preserve_range=True).astype(np.uint8)\n",
    "       \n",
    "        print(img_file)\n",
    "        \n",
    "        # Prediccion\n",
    "        mask_ = tiff.imread(os.path.join(predict_config.results_path, img_file)) / 255\n",
    "        mask_ = resize(mask_, (predict_config.height, predict_config.width), mode='constant', preserve_range=True)    \n",
    "\n",
    "        fig, axes = plt.subplots(nrows=1, ncols=2 , figsize=(20, 40)) \n",
    "        \n",
    "       \n",
    "        axes[0].imshow(img_s2)\n",
    "        axes[1].imshow(np.squeeze(mask_))\n",
    "        \n",
    "        \n",
    "        plt.show()\n",
    "        print(\"=================================================================================\")\n",
    "    except Exception as err:\n",
    "        print(err)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNKlws8+6PcuvJrSWdSmTxJ",
   "include_colab_link": true,
   "name": "3 - Predicci√≥n",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
